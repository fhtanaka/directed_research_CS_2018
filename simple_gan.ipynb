{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from utils import Logger\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from data_treatment import CreditCardDataSet\n",
    "from discriminator import *\n",
    "from generator import *\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise\n",
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): \n",
    "        return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4baf372dcb0485a933aeb38d5cae3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='File:', index=2, options=('creditcard.csv', 'data.csv', 'diabetes.csv'), value='diabetes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_dropdown = widgets.Dropdown(\n",
    "    options=glob.glob(\"*.csv\"),\n",
    "    description='File:',\n",
    "    value = 'diabetes.csv',\n",
    "    disabled=False,\n",
    ")\n",
    "display(files_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=files_dropdown.value\n",
    "if file_name == \"data.csv\":\n",
    "    message = \"Breast Cancer Wisconsin (Diagnostic) Data Set\"\n",
    "    class_name = \"diagnosis\"\n",
    "    values_names = {0: \"Benign\", 1: \"Malignant\"}\n",
    "    class_len = 33\n",
    "elif file_name == \"creditcard.csv\":\n",
    "    message = \"Credit Card Fraud Detection\"\n",
    "    class_name = \"Class\"\n",
    "    values_names = {0: \"No Frauds\", 1: \"Frauds\"}\n",
    "    class_len = 31\n",
    "elif file_name == \"diabetes.csv\":\n",
    "    message=\"Pima Indians Diabetes Database\"\n",
    "    class_name = \"Outcome\"\n",
    "    values_names = {0: \"Normal\", 1: \"Diabets\"}\n",
    "    class_len = 9\n",
    "else:\n",
    "     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error\n",
    "\n",
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "#lr= 0.0002\n",
    "d_steps = 1\n",
    "batch_size = 5\n",
    "num_epochs = 1000\n",
    "print_interval = 100\n",
    "num_test_samples = 16\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet(class_len)\n",
    "generator = GeneratorNet(class_len)\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_noise = noise(num_test_samples)\n",
    "logger = Logger(model_name=file_name[:-4], data_name=file_name[:-4] + \"_\" + class_name)\n",
    "database = CreditCardDataSet (csv_file=file_name, root_dir=\".\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(database, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "results/diabetes/0_0.txt\n",
      "Discriminator error:  tensor(0.8150, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Generator error:  tensor(0.7211, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "\n",
      "results/diabetes/0_50.txt\n",
      "Discriminator error:  tensor(27.6310, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Generator error:  tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "\n",
      "results/diabetes/0_100.txt\n",
      "Discriminator error:  tensor(27.6310, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Generator error:  tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "\n",
      "results/diabetes/0_150.txt\n",
      "Discriminator error:  tensor(27.6310, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Generator error:  tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "\n",
      "Epoch  1\n",
      "results/diabetes/1_0.txt\n",
      "Discriminator error:  tensor(27.6310, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Generator error:  tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-4360988d3db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# # Model Checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/faculdade/tsukuba/cs_studies/tsukuba_gan/utils.py\u001b[0m in \u001b[0;36msave_models\u001b[0;34m(self, generator, discriminator, epoch)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         torch.save(generator.state_dict(),\n\u001b[0;32m--> 115\u001b[0;31m                    '{}/G_epoch_{}'.format(out_dir, epoch))\n\u001b[0m\u001b[1;32m    116\u001b[0m         torch.save(discriminator.state_dict(),\n\u001b[1;32m    117\u001b[0m                    '{}/D_epoch_{}'.format(out_dir, epoch))\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "\n",
    "    for n_batch, real_batch in enumerate(data_loader):\n",
    "        # 1. Train Discriminator\n",
    "        real_data = Variable(real_batch).float()\n",
    "        if torch.cuda.is_available(): \n",
    "            real_data = real_data.cuda()\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_data.size(0))).detach()\n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
    "                                                                real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        # Log error\n",
    "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "\n",
    "        # Display Progress\n",
    "\n",
    "        if (n_batch) % print_intervaç == 0:\n",
    "            filename = \"results/\" + file_name[:-4] + \"/\" + str(epoch) + \"_\" + str(n_batch) + \".txt\"\n",
    "            print(filename)\n",
    "            file = open(filename, \"w\")\n",
    "            print(\"Discriminator error: \", d_error)\n",
    "            print(\"Generator error: \", g_error)\n",
    "            print(\"\")\n",
    "\n",
    "            file.write(\"Discriminator error: \" + str(d_error) + \"\\n\")\n",
    "            file.write(\"Generator error: \" + str(g_error) + \"\\n\")\n",
    "            file.write(\"Points: \" + str(fake_data) + \"\\n\\n\\n\")\n",
    "        #     #display.clear_output(True)\n",
    "        #     # Display Images\n",
    "        #     test_images = generator(test_noise).data.cpu()\n",
    "        #     logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
    "        #     # Display status Logs\n",
    "        #     #logger.display_status(epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake)\n",
    "        # # Model Checkpoints\n",
    "\n",
    "        logger.save_models(generator, discriminator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
